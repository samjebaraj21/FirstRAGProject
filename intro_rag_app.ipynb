{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-27T04:09:15.680383Z",
     "start_time": "2025-12-27T04:09:14.998602Z"
    }
   },
   "source": "!ollama pull llama3.2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠋ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠙ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠸ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠸ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest \u001B[K\r\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001B[K\r\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001B[K\r\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001B[K\r\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001B[K\r\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001B[K\r\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001B[K\r\n",
      "verifying sha256 digest \u001B[K\r\n",
      "writing manifest \u001B[K\r\n",
      "success \u001B[K\u001B[?25h\u001B[?2026l\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T04:09:59.463587Z",
     "start_time": "2025-12-27T04:09:42.098968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test Ollama\n",
    "\n",
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "response: ChatResponse = chat(model='llama3.2', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'What is the capital of France? Can you also give me that city\\'s history?',\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])"
   ],
   "id": "59202d194be51827",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris. Here's a brief overview of its rich and fascinating history:\n",
      "\n",
      "**Ancient Times (52 BC - 486 AD)**\n",
      "\n",
      "Paris was founded by the Celtic tribe known as the Parisii in the 3rd century BC. The Romans conquered the city in 52 BC and renamed it Lutetia Parisiorum, which translates to \"Lutece of the Parisians.\" During this period, Paris became an important center for trade, culture, and politics.\n",
      "\n",
      "**Middle Ages (486 - 1492)**\n",
      "\n",
      "In the 5th century AD, Paris was conquered by the Franks, a Germanic tribe. The city became an important center for Christianity, with the construction of several churches and monasteries. In the 9th century, Charlemagne, King of the Franks, made Paris his capital.\n",
      "\n",
      "**Renaissance and Enlightenment (1492 - 1789)**\n",
      "\n",
      "During the Renaissance, Paris became a hub for art, literature, and science. The city was home to prominent figures such as Leonardo da Vinci, Michelangelo, and Voltaire. The French Revolution in 1789 marked a significant turning point in Paris' history, with the storming of the Bastille and the establishment of the First French Republic.\n",
      "\n",
      "**Napoleon Bonaparte and the Empire (1804 - 1815)**\n",
      "\n",
      "In 1804, Napoleon Bonaparte crowned himself Emperor of France, marking the beginning of the Napoleonic Empire. Paris became a symbol of imperial power and culture, with grand buildings such as the Louvre and the Arc de Triomphe.\n",
      "\n",
      "**19th and 20th Centuries (1815 - 1945)**\n",
      "\n",
      "The 19th century saw significant urbanization and industrialization in Paris, with the construction of the Paris Metro and the development of the city's famous boulevards. During World War I, Paris was occupied by German forces, while during World War II, the city suffered greatly under Nazi occupation.\n",
      "\n",
      "**Modern Era (1945 - present)**\n",
      "\n",
      "In the aftermath of World War II, Paris played a significant role in rebuilding France and becoming a hub for international diplomacy and culture. Today, Paris is one of the most visited cities in the world, known for its iconic landmarks, museums, fashion, cuisine, and rich history.\n",
      "\n",
      "Some notable historical events and figures associated with Paris include:\n",
      "\n",
      "* The French Revolution (1789)\n",
      "* Napoleon Bonaparte's coronation (1804)\n",
      "* The construction of the Eiffel Tower (1889)\n",
      "* World War I and II\n",
      "* The rise of modern art movements such as Impressionism and Surrealism\n",
      "* Famous writers and artists, including Victor Hugo, Gustave Courbet, and Claude Monet\n",
      "\n",
      "This is just a brief overview of Paris' fascinating history. If you'd like to know more about specific aspects or periods, feel free to ask!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T04:12:02.892380Z",
     "start_time": "2025-12-27T04:12:02.427489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, MarkdownHeaderTextSplitter\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "# --- Load the text and split into chunks ---\n",
    "loader = UnstructuredMarkdownLoader(\"output.md\")\n",
    "data = loader.load()\n",
    "\n",
    "headers_to_split_on = [(\"#\", \"Header 1\"), (\"##\", \"Header 2\"), (\"###\", \"Header 3\")]\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "md_header_splits = markdown_splitter.split_text(data[0].page_content)\n",
    "\n",
    "# Add a second layer of splitting to stay under 40KB\n",
    "# 2000 characters is roughly 2-3KB, well within Pinecone's 40KB limit\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=500\n",
    ")\n",
    "\n",
    "# Apply the second splitter to the header-splits, preserving metadata on each chunk\n",
    "final_docs = text_splitter.split_documents(md_header_splits)"
   ],
   "id": "2b9fdd2555ad4779",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T04:12:35.337510Z",
     "start_time": "2025-12-27T04:12:11.582106Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install \"torch>=2.0\" \"transformers>=4.40\" \"sentence-transformers>=3.0\" \"langchain-huggingface\" \"langchain-pinecone\" \"python-dotenv\"",
   "id": "a353da543d6cf0fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch>=2.0\r\n",
      "  Obtaining dependency information for torch>=2.0 from https://files.pythonhosted.org/packages/6e/ab/07739fd776618e5882661d04c43f5b5586323e2f6a2d7d84aac20d8f20bd/torch-2.9.1-cp312-none-macosx_11_0_arm64.whl.metadata\r\n",
      "  Using cached torch-2.9.1-cp312-none-macosx_11_0_arm64.whl.metadata (30 kB)\r\n",
      "Collecting transformers>=4.40\r\n",
      "  Obtaining dependency information for transformers>=4.40 from https://files.pythonhosted.org/packages/6a/6b/2f416568b3c4c91c96e5a365d164f8a4a4a88030aa8ab4644181fdadce97/transformers-4.57.3-py3-none-any.whl.metadata\r\n",
      "  Using cached transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\r\n",
      "Collecting sentence-transformers>=3.0\r\n",
      "  Obtaining dependency information for sentence-transformers>=3.0 from https://files.pythonhosted.org/packages/40/d0/3b2897ef6a0c0c801e9fecca26bcc77081648e38e8c772885ebdd8d7d252/sentence_transformers-5.2.0-py3-none-any.whl.metadata\r\n",
      "  Using cached sentence_transformers-5.2.0-py3-none-any.whl.metadata (16 kB)\r\n",
      "Collecting langchain-huggingface\r\n",
      "  Obtaining dependency information for langchain-huggingface from https://files.pythonhosted.org/packages/81/ce/502157ef7390a31cc67e5873ad66e737a25d1d33fcf6936e5c9a0a451409/langchain_huggingface-1.2.0-py3-none-any.whl.metadata\r\n",
      "  Using cached langchain_huggingface-1.2.0-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Collecting langchain-pinecone\r\n",
      "  Obtaining dependency information for langchain-pinecone from https://files.pythonhosted.org/packages/1e/cf/27ec504e2fa92e73d49bc49f4345d82e5b6e75158c56092f5140f6afc8bd/langchain_pinecone-0.2.13-py3-none-any.whl.metadata\r\n",
      "  Using cached langchain_pinecone-0.2.13-py3-none-any.whl.metadata (8.6 kB)\r\n",
      "Requirement already satisfied: python-dotenv in ./venv/lib/python3.12/site-packages (1.2.1)\r\n",
      "Collecting filelock (from torch>=2.0)\r\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/e3/7f/a1a97644e39e7316d850784c642093c99df1290a460df4ede27659056834/filelock-3.20.1-py3-none-any.whl.metadata\r\n",
      "  Using cached filelock-3.20.1-py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./venv/lib/python3.12/site-packages (from torch>=2.0) (4.15.0)\r\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.12/site-packages (from torch>=2.0) (80.9.0)\r\n",
      "Collecting sympy>=1.13.3 (from torch>=2.0)\r\n",
      "  Obtaining dependency information for sympy>=1.13.3 from https://files.pythonhosted.org/packages/a2/09/77d55d46fd61b4a135c444fc97158ef34a095e5681d0a6c10b75bf356191/sympy-1.14.0-py3-none-any.whl.metadata\r\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./venv/lib/python3.12/site-packages (from torch>=2.0) (3.6.1)\r\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.12/site-packages (from torch>=2.0) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./venv/lib/python3.12/site-packages (from torch>=2.0) (2025.12.0)\r\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers>=4.40)\r\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.34.0 from https://files.pythonhosted.org/packages/cb/bd/1a875e0d592d447cbc02805fd3fe0f497714d6a2583f59d14fa9ebad96eb/huggingface_hub-0.36.0-py3-none-any.whl.metadata\r\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.12/site-packages (from transformers>=4.40) (2.4.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.12/site-packages (from transformers>=4.40) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.12/site-packages (from transformers>=4.40) (6.0.3)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.12/site-packages (from transformers>=4.40) (2025.11.3)\r\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.12/site-packages (from transformers>=4.40) (2.32.5)\r\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers>=4.40)\r\n",
      "  Obtaining dependency information for tokenizers<=0.23.0,>=0.22.0 from https://files.pythonhosted.org/packages/1c/58/2aa8c874d02b974990e89ff95826a4852a8b2a273c7d1b4411cdd45a4565/tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl.metadata\r\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\r\n",
      "Collecting safetensors>=0.4.3 (from transformers>=4.40)\r\n",
      "  Obtaining dependency information for safetensors>=0.4.3 from https://files.pythonhosted.org/packages/e8/00/374c0c068e30cd31f1e1b46b4b5738168ec79e7689ca82ee93ddfea05109/safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl.metadata\r\n",
      "  Using cached safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.12/site-packages (from transformers>=4.40) (4.67.1)\r\n",
      "Collecting scikit-learn (from sentence-transformers>=3.0)\r\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/49/d8/9be608c6024d021041c7f0b3928d4749a706f4e2c3832bbede4fb4f58c95/scikit_learn-1.8.0-cp312-cp312-macosx_12_0_arm64.whl.metadata\r\n",
      "  Using cached scikit_learn-1.8.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (11 kB)\r\n",
      "Collecting scipy (from sentence-transformers>=3.0)\r\n",
      "  Obtaining dependency information for scipy from https://files.pythonhosted.org/packages/96/5e/36bf3f0ac298187d1ceadde9051177d6a4fe4d507e8f59067dc9dd39e650/scipy-1.16.3-cp312-cp312-macosx_14_0_arm64.whl.metadata\r\n",
      "  Using cached scipy-1.16.3-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\r\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.0 in ./venv/lib/python3.12/site-packages (from langchain-huggingface) (1.2.5)\r\n",
      "Collecting pinecone[asyncio]<8.0.0,>=6.0.0 (from langchain-pinecone)\r\n",
      "  Obtaining dependency information for pinecone[asyncio]<8.0.0,>=6.0.0 from https://files.pythonhosted.org/packages/b7/a6/c5d54a5fb1de3983a8739c1a1660e7a7074db2cbadfa875b823fcf29b629/pinecone-7.3.0-py3-none-any.whl.metadata\r\n",
      "  Using cached pinecone-7.3.0-py3-none-any.whl.metadata (9.5 kB)\r\n",
      "Collecting langchain-openai>=0.3.11 (from langchain-pinecone)\r\n",
      "  Obtaining dependency information for langchain-openai>=0.3.11 from https://files.pythonhosted.org/packages/db/5b/1f6521df83c1a8e8d3f52351883b59683e179c0aa1bec75d0a77a394c9e7/langchain_openai-1.1.6-py3-none-any.whl.metadata\r\n",
      "  Using cached langchain_openai-1.1.6-py3-none-any.whl.metadata (2.6 kB)\r\n",
      "Requirement already satisfied: httpx>=0.28.0 in ./venv/lib/python3.12/site-packages (from langchain-pinecone) (0.28.1)\r\n",
      "Collecting simsimd>=5.9.11 (from langchain-pinecone)\r\n",
      "  Obtaining dependency information for simsimd>=5.9.11 from https://files.pythonhosted.org/packages/6b/55/cd16b42861c58c52b39da6806b820ed48a817ce966fc9ed4ad5c16543519/simsimd-6.5.12-cp312-cp312-macosx_11_0_arm64.whl.metadata\r\n",
      "  Using cached simsimd-6.5.12-cp312-cp312-macosx_11_0_arm64.whl.metadata (70 kB)\r\n",
      "Requirement already satisfied: pydantic>=2.11.1 in ./venv/lib/python3.12/site-packages (from langchain-pinecone) (2.12.5)\r\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.12/site-packages (from httpx>=0.28.0->langchain-pinecone) (4.12.0)\r\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from httpx>=0.28.0->langchain-pinecone) (2025.11.12)\r\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx>=0.28.0->langchain-pinecone) (1.0.9)\r\n",
      "Requirement already satisfied: idna in ./venv/lib/python3.12/site-packages (from httpx>=0.28.0->langchain-pinecone) (3.11)\r\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.28.0->langchain-pinecone) (0.16.0)\r\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers>=4.40)\r\n",
      "  Obtaining dependency information for hf-xet<2.0.0,>=1.1.3 from https://files.pythonhosted.org/packages/7f/8c/c5becfa53234299bc2210ba314eaaae36c2875e0045809b82e40a9544f0c/hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata\r\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.9 kB)\r\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.33)\r\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in ./venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.5.1)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (9.1.2)\r\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in ./venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.12.0)\r\n",
      "Collecting openai<3.0.0,>=1.109.1 (from langchain-openai>=0.3.11->langchain-pinecone)\r\n",
      "  Obtaining dependency information for openai<3.0.0,>=1.109.1 from https://files.pythonhosted.org/packages/27/4b/7c1a00c2c3fbd004253937f7520f692a9650767aa73894d7a34f0d65d3f4/openai-2.14.0-py3-none-any.whl.metadata\r\n",
      "  Using cached openai-2.14.0-py3-none-any.whl.metadata (29 kB)\r\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in ./venv/lib/python3.12/site-packages (from langchain-openai>=0.3.11->langchain-pinecone) (0.12.0)\r\n",
      "Requirement already satisfied: aiohttp>=3.9.0 in ./venv/lib/python3.12/site-packages (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (3.13.2)\r\n",
      "Collecting aiohttp-retry<3.0.0,>=2.9.1 (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone)\r\n",
      "  Obtaining dependency information for aiohttp-retry<3.0.0,>=2.9.1 from https://files.pythonhosted.org/packages/1a/99/84ba7273339d0f3dfa57901b846489d2e5c2cd731470167757f1935fffbd/aiohttp_retry-2.9.1-py3-none-any.whl.metadata\r\n",
      "  Using cached aiohttp_retry-2.9.1-py3-none-any.whl.metadata (8.8 kB)\r\n",
      "Collecting pinecone-plugin-assistant<2.0.0,>=1.6.0 (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone)\r\n",
      "  Obtaining dependency information for pinecone-plugin-assistant<2.0.0,>=1.6.0 from https://files.pythonhosted.org/packages/dd/49/62ab8e2f9098bf8593e36bbe6e729fcc0500bafca7d88be7b62eac66c8b0/pinecone_plugin_assistant-1.8.0-py3-none-any.whl.metadata\r\n",
      "  Using cached pinecone_plugin_assistant-1.8.0-py3-none-any.whl.metadata (30 kB)\r\n",
      "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone)\r\n",
      "  Obtaining dependency information for pinecone-plugin-interface<0.0.8,>=0.0.7 from https://files.pythonhosted.org/packages/3b/1d/a21fdfcd6d022cb64cef5c2a29ee6691c6c103c4566b41646b080b7536a5/pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata\r\n",
      "  Using cached pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\r\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in ./venv/lib/python3.12/site-packages (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (2.9.0.post0)\r\n",
      "Requirement already satisfied: urllib3>=1.26.5 in ./venv/lib/python3.12/site-packages (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (2.6.2)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic>=2.11.1->langchain-pinecone) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./venv/lib/python3.12/site-packages (from pydantic>=2.11.1->langchain-pinecone) (2.41.5)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./venv/lib/python3.12/site-packages (from pydantic>=2.11.1->langchain-pinecone) (0.4.2)\r\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.0)\r\n",
      "  Obtaining dependency information for mpmath<1.4,>=1.1.0 from https://files.pythonhosted.org/packages/43/e3/7d92a15f894aa0c9c4b49b8ee9ac9850d6e63b03c9c32c0367a13ae62209/mpmath-1.3.0-py3-none-any.whl.metadata\r\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2->torch>=2.0) (3.0.3)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests->transformers>=4.40) (3.4.4)\r\n",
      "Requirement already satisfied: joblib>=1.3.0 in ./venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers>=3.0) (1.5.3)\r\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn->sentence-transformers>=3.0)\r\n",
      "  Obtaining dependency information for threadpoolctl>=3.2.0 from https://files.pythonhosted.org/packages/32/d5/f9a850d79b0851d1d4ef6456097579a9005b31fea68726a4ae5f2d82ddd9/threadpoolctl-3.6.0-py3-none-any.whl.metadata\r\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./venv/lib/python3.12/site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./venv/lib/python3.12/site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (1.4.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (25.4.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.12/site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (1.8.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.12/site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (6.7.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.12/site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (0.4.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.12/site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (1.22.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (3.0.0)\r\n",
      "Requirement already satisfied: orjson>=3.9.14 in ./venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (3.11.5)\r\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.0.0)\r\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.25.0)\r\n",
      "Collecting distro<2,>=1.7.0 (from openai<3.0.0,>=1.109.1->langchain-openai>=0.3.11->langchain-pinecone)\r\n",
      "  Obtaining dependency information for distro<2,>=1.7.0 from https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl.metadata\r\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Collecting jiter<1,>=0.10.0 (from openai<3.0.0,>=1.109.1->langchain-openai>=0.3.11->langchain-pinecone)\r\n",
      "  Obtaining dependency information for jiter<1,>=0.10.0 from https://files.pythonhosted.org/packages/98/6e/e8efa0e78de00db0aee82c0cf9e8b3f2027efd7f8a71f859d8f4be8e98ef/jiter-0.12.0-cp312-cp312-macosx_11_0_arm64.whl.metadata\r\n",
      "  Using cached jiter-0.12.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.2 kB)\r\n",
      "Collecting sniffio (from openai<3.0.0,>=1.109.1->langchain-openai>=0.3.11->langchain-pinecone)\r\n",
      "  Obtaining dependency information for sniffio from https://files.pythonhosted.org/packages/e9/44/75a9c9421471a6c4805dbf2356f7c181a29c1879239abab1ea2cc8f38b40/sniffio-1.3.1-py3-none-any.whl.metadata\r\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\r\n",
      "Collecting packaging>=20.0 (from transformers>=4.40)\r\n",
      "  Obtaining dependency information for packaging>=20.0 from https://files.pythonhosted.org/packages/88/ef/eb23f262cca3c0c4eb7ab1933c3b1f03d021f2c48f54763065b6f0e321be/packaging-24.2-py3-none-any.whl.metadata\r\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.5.3->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (1.17.0)\r\n",
      "Using cached torch-2.9.1-cp312-none-macosx_11_0_arm64.whl (74.5 MB)\r\n",
      "Using cached transformers-4.57.3-py3-none-any.whl (12.0 MB)\r\n",
      "Using cached sentence_transformers-5.2.0-py3-none-any.whl (493 kB)\r\n",
      "Using cached langchain_huggingface-1.2.0-py3-none-any.whl (30 kB)\r\n",
      "Using cached langchain_pinecone-0.2.13-py3-none-any.whl (26 kB)\r\n",
      "Using cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\r\n",
      "Using cached langchain_openai-1.1.6-py3-none-any.whl (84 kB)\r\n",
      "Using cached safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl (447 kB)\r\n",
      "Using cached simsimd-6.5.12-cp312-cp312-macosx_11_0_arm64.whl (94 kB)\r\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\r\n",
      "Using cached tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl (2.9 MB)\r\n",
      "Using cached filelock-3.20.1-py3-none-any.whl (16 kB)\r\n",
      "Using cached scikit_learn-1.8.0-cp312-cp312-macosx_12_0_arm64.whl (8.1 MB)\r\n",
      "Using cached scipy-1.16.3-cp312-cp312-macosx_14_0_arm64.whl (20.9 MB)\r\n",
      "Using cached aiohttp_retry-2.9.1-py3-none-any.whl (10.0 kB)\r\n",
      "Using cached hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl (2.7 MB)\r\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "Using cached openai-2.14.0-py3-none-any.whl (1.1 MB)\r\n",
      "Using cached pinecone_plugin_assistant-1.8.0-py3-none-any.whl (259 kB)\r\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\r\n",
      "Using cached pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\r\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\r\n",
      "Using cached pinecone-7.3.0-py3-none-any.whl (587 kB)\r\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\r\n",
      "Using cached jiter-0.12.0-cp312-cp312-macosx_11_0_arm64.whl (319 kB)\r\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\r\n",
      "Installing collected packages: simsimd, mpmath, threadpoolctl, sympy, sniffio, scipy, safetensors, pinecone-plugin-interface, packaging, jiter, hf-xet, filelock, distro, torch, scikit-learn, pinecone-plugin-assistant, huggingface-hub, tokenizers, pinecone, openai, aiohttp-retry, transformers, sentence-transformers, langchain-openai, langchain-huggingface, langchain-pinecone\r\n",
      "  Attempting uninstall: packaging\r\n",
      "    Found existing installation: packaging 25.0\r\n",
      "    Uninstalling packaging-25.0:\r\n",
      "      Successfully uninstalled packaging-25.0\r\n",
      "Successfully installed aiohttp-retry-2.9.1 distro-1.9.0 filelock-3.20.1 hf-xet-1.2.0 huggingface-hub-0.36.0 jiter-0.12.0 langchain-huggingface-1.2.0 langchain-openai-1.1.6 langchain-pinecone-0.2.13 mpmath-1.3.0 openai-2.14.0 packaging-24.2 pinecone-7.3.0 pinecone-plugin-assistant-1.8.0 pinecone-plugin-interface-0.0.7 safetensors-0.7.0 scikit-learn-1.8.0 scipy-1.16.3 sentence-transformers-5.2.0 simsimd-6.5.12 sniffio-1.3.1 sympy-1.14.0 threadpoolctl-3.6.0 tokenizers-0.22.1 torch-2.9.1 transformers-4.57.3\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T04:13:46.057349Z",
     "start_time": "2025-12-27T04:13:17.879829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- For import issues with torch library ---\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "if not hasattr(lr_scheduler, \"LRScheduler\"):\n",
    "    lr_scheduler.LRScheduler = lr_scheduler._LRScheduler\n",
    "\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# --- Pull API Keys ---\n",
    "load_dotenv(\"info.env\")\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "\n",
    "# Model matches 384 dimensions\n",
    "embed_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embed_model_name)\n",
    "\n",
    "# Create index\n",
    "index_name = \"rag-test-index\"\n",
    "\n",
    "# Force a clean start if the dimensions are wrong\n",
    "if index_name in [idx.name for idx in pc.list_indexes()]:\n",
    "    desc = pc.describe_index(index_name)\n",
    "    if desc.dimension != 384:\n",
    "        print(f\"Index has wrong dimension ({desc.dimension}). Deleting...\")\n",
    "        pc.delete_index(index_name)\n",
    "        time.sleep(5) # Wait for Pinecone to clear\n",
    "\n",
    "# Create the correct 384-dimension index\n",
    "if index_name not in [idx.name for idx in pc.list_indexes()]:\n",
    "    print(f\"Creating new 384-dimension index...\")\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric='cosine',\n",
    "        spec=ServerlessSpec(cloud='aws', region='us-east-1')\n",
    "    )\n",
    "\n",
    "# Store final_docs\n",
    "vector_store = PineconeVectorStore.from_documents(\n",
    "    final_docs,\n",
    "    embeddings,\n",
    "    index_name=index_name,\n",
    ")\n",
    "print(f\"Upsert successful! Total chunks created: {len(final_docs)}\")"
   ],
   "id": "d36e1772c6a69719",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert successful! Total chunks created: 38\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T04:14:29.286771Z",
     "start_time": "2025-12-27T04:14:14.842814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Initialize the LLM using Ollama\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# --- Create the RAG Pipeline ---\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {input}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Define the \"Chain\" using the pipe syntax with the Pinecone vector store\n",
    "retriever = vector_store.as_retriever(earch_kwargs={\"k\": 7})\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"input\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# --- Run the Pipeline ---\n",
    "response = rag_chain.invoke(\"What are David Mitchell's rules of trading stocks, what are some general facts, and what are some important patterns to know?\")\n",
    "print(response)"
   ],
   "id": "73e539a5ffa664e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided context, David Mitchell's Stock Rules include:\n",
      "\n",
      "1. Go through his stock rules and keep them by your computer.\n",
      "2. Setup charts by TRADEway (charts.bytradeway.com).\n",
      "3. Open a trading account (tradeway.com/tradier).\n",
      "4. Wire funds (put money in your trading account).\n",
      "5. Connect charts by TRADEway with Tradier Account.\n",
      "\n",
      "Some general facts mentioned include:\n",
      "\n",
      "1. The importance of diversification, which is often overemphasized and can be a myth.\n",
      "2. The need to have skill-sets when trading stocks, rather than relying on products sold by financial advisors.\n",
      "3. Quotes from Warren Buffet and Philip Fisher about diversification.\n",
      "\n",
      "Important patterns to know include:\n",
      "\n",
      "1. The TRADEway Three Legged Trading Table:\n",
      "\t* Fundamentals: Shows what to buy, including earnings per share, relative price strength, industry group ratings, return on equity, and accumulation/distribution.\n",
      "\t* Technicals: Shows when to buy and sell fundamentally sound stocks, using charts to measure price and strength movements over time.\n",
      "2. A strong bullish pattern in the chart of Netsuite Inc., showing a consistent upward trend with periodic consolidations and breakouts.\n",
      "3. A range-bound market with potential breakout points in the chart of General Dynamics Corp., displaying horizontal support and resistance levels.\n",
      "\n",
      "These patterns are mentioned in the context of analyzing stock charts using TRADEway's charts and Tradier Account.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a98ec0efd819d23f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
